---
title: Adversarial Interpretation of Bayesian Inference
abstract: 'We build on the optimization-centric view on Bayesian inference advocated
  by Knoblauch et al. (2019). Thinking about Bayesian and generalized Bayesian posteriors
  as the solutions to a regularized minimization problem allows us to answer an intriguing
  question: If minimization is the primal problem, then what is its dual?  By deriving
  the Fenchel dual of the problem, we demonstrate that this dual corresponds to an
  adversarial game:  In the dual space, the prior becomes the cost function for an
  adversary that seeks to perturb the likelihood [loss] function targeted by standard
  [generalized] Bayesian inference.  This implies that Bayes-like procedures are adversarially
  robustâ€”providing another firm theoretical foundation for their empirical performance.
  Our contributions are foundational, and apply to a wide-ranging set of Machine Learning
  methods. This includes standard Bayesian inference, generalized Bayesian and Gibbs
  posteriors (Bissiri et al., 2016), as well as a diverse set of other methods including
  Generalized Variational Inference (Knoblauch et al., 2019) and the Wasserstein Autoencoder
  (Tolstikhin et al., 2017).'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: husain22a
month: 0
tex_title: Adversarial Interpretation of Bayesian Inference
firstpage: 553
lastpage: 572
page: 553-572
order: 553
cycles: false
bibtex_author: Husain, Hisham and Knoblauch, Jeremias
author:
- given: Hisham
  family: Husain
- given: Jeremias
  family: Knoblauch
date: 2022-03-20
address:
container-title: Proceedings of The 33rd International Conference on Algorithmic Learning
  Theory
volume: '167'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 3
  - 20
pdf: https://proceedings.mlr.press/v167/husain22a/husain22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
