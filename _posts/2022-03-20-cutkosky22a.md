---
title: Leveraging Initial Hints for Free in Stochastic Linear Bandits
abstract: " We study the setting of optimizing with bandit feedback with additional
  prior knowledge provided to the learner in the form of an initial hint of the optimal
  action. We present a novel algorithm for stochastic linear bandits that uses this
  hint to improve its regret to $\\tilde O(\\sqrt{T})$ when the hint is accurate,
  while maintaining a minimax-optimal $\\tilde O(d\\sqrt{T})$ regret independent of
  the quality of the hint. Furthermore, we provide a Pareto frontier of tight tradeoffs
  between best-case and worst-case regret, with matching lower bounds. Perhaps surprisingly,
  our work shows that leveraging a hint shows provable gains without sacrificing worst-case
  performance, implying that our algorithm adapts to the quality of the hint for free.
  We also provide an extension of our algorithm to the case of $m$ initial hints,
  showing that we can achieve a $\\tilde O(m^{2/3}\\sqrt{T})$ regret."
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cutkosky22a
month: 0
tex_title: Leveraging Initial Hints for Free in Stochastic Linear Bandits
firstpage: 282
lastpage: 318
page: 282-318
order: 282
cycles: false
bibtex_author: Cutkosky, Ashok and Dann, Chris and Das, Abhimanyu and Zhang, Qiuyi
author:
- given: Ashok
  family: Cutkosky
- given: Chris
  family: Dann
- given: Abhimanyu
  family: Das
- given: Qiuyi
  family: Zhang
date: 2022-03-20
address:
container-title: Proceedings of The 33rd International Conference on Algorithmic Learning
  Theory
volume: '167'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 3
  - 20
pdf: https://proceedings.mlr.press/v167/cutkosky22a/cutkosky22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
